---
title: "Google Store Transaction Revenue Prediction "
author: "Seyoung Jung"
date: "7/31/2020"
output: rmarkdown::github_document
---


```{r, echo = FALSE}
knitr::opts_chunk$set(
  fig.path = "README_figs/README-"
)
```




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

***

# 1 Introduction


As we all know, Google is one of the biggest tech giants. They specialize in internet-related services, and people all around the world use them on a daily basis. Having billions of active users allows them to accumulate massive data, which plays a critical role of further developing their businesses rapidly. 

Not only internet-related services, Google operates Google Store (GStore in short) which is an online retailer that sells not only hardwares including phones, Chromecasts, and speakers, but also accessories such as chargers, earbuds, etc. You can explore GStore [here](https://store.google.com/). 

In this project, we build a model that predicts transaction revenues from each visitors. We build XGBoost and LightGBM models. The dataset used for this project can be found [here](https://www.kaggle.com/c/ga-customer-revenue-prediction). The third chapter describes how the dataset looks like. You will see that our target variable, transactionRevenue, is a million times of USD. The dataset contains JSON formatted columns.If you parse the columns, we get 55 variables including pageviews, bounce, sessionId, etc. They provide two sets of csv files: training set with target variables (transactionRevenue) and test set without target variables. However, in this project, we use only training set to see how well our model predicts transaction revenues.  
 



***

# 2 Preparation


First, let's load libraries that we are going to use for this project.
```{r, message=FALSE, warning=FALSE}
library(readr)        
library(dplyr)       
library(stringr)      
library(ggplot2)      
library(scales)       
library(gridExtra)    
library(tidyr)
library(jsonlite)     
library(Hmisc)        
library(lubridate)
library(forcats)
library(magrittr)    
library(janitor)      
library(lightgbm)
library(xgboost)
library(caret)
library(Matrix)
```

And then load the dataset to analyze.
```{r, message=FALSE}
GA_data <- read_csv("train_v1.csv", n_max=1000000)
```

Since the dataset contains JSON columns (device, geoNetwork, totals, and trafficSource), we are going to parse them and remove the original columns. And then we will combine the new dataset with the original dataset. 
```{r, message=FALSE}
device_df <- paste("[", paste(GA_data$device, collapse = ","), "]") %>% fromJSON(flatten = T)
geoNetwork_df <- paste("[", paste(GA_data$geoNetwork, collapse = ","), "]") %>% fromJSON(flatten = T)
totals_df <- paste("[", paste(GA_data$totals, collapse = ","), "]") %>% fromJSON(flatten = T)
trafficSource_df <- paste("[", paste(GA_data$trafficSource, collapse = ","), "]") %>% fromJSON(flatten = T)

GA_data <- GA_data[, -c(3, 5, 8, 9)]
GA_combined <- cbind(GA_data, device_df, geoNetwork_df, totals_df, trafficSource_df)
rm(device_df, geoNetwork_df, totals_df, trafficSource_df)
```



Let's have a glimpse of the structure of the dataset. Below we can see that most of features are character features and a lot of them have constant data. 
```{r}
glimpse(GA_combined)
```


We will remove constant features, because they will not be useful to our predictive model.  
```{r, message = FALSE}
nonconstant_data <- remove_constant(GA_combined, na.rm = FALSE, quiet = TRUE)
removed_columns <- setdiff(names(GA_combined), names(nonconstant_data))
paste0(length(removed_columns), " features have been removed")
```

We have 6 different types of missing values in this dataset; "(not set)", "not available in demo dataset", "(not provided)", "(none)", "unknown.unknown", and "<NA>". We will replace them with "<NA>". 
```{r, message = FALSE, warning = FALSE}
missingvals <- function(x) x %in% c("(not set)", "not available in demo dataset", "(not provided)", "(none)", "unknown.unknown", "<NA>")

nonconstant_data %<>% mutate_all(funs(ifelse(missingvals(.), NA, .)))
```




The ratios of NA's in each feature from the dataset are as follows. You can see that approximately 98.73% of our target variable, transactionRevenue, is missing. It means that 1.27% of visits had transaction revenues. 
```{r, message = FALSE}
options(scipen = 999) 
NA_columns <- sapply(nonconstant_data, function(x) {sum(is.na(x))/length(x)})
NA_columns[order(-NA_columns)]  %>% head(26) 
```

Next, we will convert variables accordingly. 
```{r, message = FALSE, warning = FALSE}
nonconstant_data$date <- ymd(nonconstant_data$date)
cols_toFactor <- c("channelGrouping", "browser", "operatingSystem", "deviceCategory", "continent", "medium")
nonconstant_data %<>% mutate_each_(funs(factor(.)),cols_toFactor)
cols_toNumeric <- c("hits", "pageviews", "transactionRevenue")
nonconstant_data %<>% mutate_each_(funs(as.numeric),cols_toNumeric)
```

We can calculate the USD ($) by dividing transactionRevenue by 1 million. We will create a new feature "USD" and add it to our dataset. 
```{r, message = FALSE}
nonconstant_data$USD <- nonconstant_data$transactionRevenue/10^6
```


Data sampling (75%: Training set / 25%: Test set) 
```{r, message = FALSE}
sample_size <- floor(0.75 * nrow(nonconstant_data))
set.seed(209)
sampling_data <- sample(seq_len(nrow(nonconstant_data)), size = sample_size)
train_set <- nonconstant_data[sampling_data, ]
test_set <- nonconstant_data[-sampling_data, ]
paste0("The training set has ", nrow(train_set), " sessions, and the test set has ", nrow(test_set), " sessions")
```

```{r, message = FALSE, echo=FALSE}
rm(GA_data, sample_size, sampling_data, cols_toFactor, cols_toNumeric)

```



***


# 3 Exploratory Data Analysis
In this section, we will investigate on our data to understand how it looks like and find patterns using various methods such as visualizations. Feature names explained below are excerpted from [here](https://support.google.com/analytics/answer/3437719?hl=en)

* __channelGrouping__: The Default Channel Group associated with an end user's session for this View.
* __date__: The date of the session in YYYYMMDD format.
* __fullVisitorId__:The unique visitor ID (also known as client ID). 
* __sessionId__: A unique identifier for this visit to the store. 
* __visitId__: An identifier for this session. This is part of the value usually stored as the _utmb cookie. This is only unique to the user. For a completely unique ID, you should use a combination of fullVisitorId and visitId.
* __visitNumber__: The session number for this user. If this is the first session, then this is set to 1.
* __visitStartTime__: The timestamp (expressed as POSIX time).
* __browser__: The browser used (e.g., "Chrome" or "Firefox").
* __operatingSystem__: The operating system of the device (e.g., "Macintosh" or "Windows").
* __isMobile__: If the user is on a mobile device, this value is true, otherwise false.
* __deviceCategory__: The type of device (Mobile, Tablet, Desktop).
* __continent__: The continent from which sessions originated, based on IP address.
* __subContinent__: 	The sub-continent from which sessions originated, based on IP address of the visitor.
* __country__: The country from which sessions originated, based on IP address.
* __region__: The region from which sessions originate, derived from IP addresses. In the U.S., a region is a state, such as New York.
* __metro__: The Designated Market Area (DMA) from which sessions originate.
* __city__: Users' city, derived from their IP addresses or Geographical IDs.
* __networkDomain__: The domain name of user's ISP, derived from the domain name registered to the ISP's IP address.
* __hits__: This row and nested fields are populated for any and all types of hits.
* __pageviews__: Total number of pageviews within the session.
* __bounces__: Total bounces (for convenience). For a bounced session, the value is 1, otherwise it is null.
* __newVisits__: Total number of new users in session (for convenience). If this is the first visit, this value is 1, otherwise it is null.
* __transactionRevenue__: Total transaction revenue, expressed as the value passed to Analytics multiplied by 10^6 (e.g., 2.40 would be given as 2400000).
* __campaign__: 	The campaign value. Usually set by the utm_campaign URL parameter.
* __source__: The source of the traffic source. Could be the name of the search engine, the referring hostname, or a value of the utm_source URL parameter.
* __medium__: The medium of the traffic source. Could be "organic", "cpc", "referral", or the value of the utm_medium URL parameter.
* __keyword__: The keyword of the traffic source, usually set when the trafficSource.medium is "organic" or "cpc". Can be set by the utm_term URL parameter.
* __isTrueDirect__: True if the source of the session was Direct (meaning the user typed the name of your website URL into the browser or came to your site via a bookmark), This field will also be true if 2 successive but distinct sessions have exactly the same campaign details. Otherwise NULL.
* __referralPath__: If trafficSource.medium is "referral", then this is set to the path of the referrer. (The host name of the referrer is in trafficSource.source.)
* __adContent__: The ad content of the traffic source. Can be set by the utm_content URL parameter.
* __campaignCode__: Value of the utm_id campaign tracking parameter, used for manual campaign tracking.
* __adwordsClickInfo.page__: 	Page number in search results where the ad was shown.
* __adwordsClickInfo.slot__: Position of the Ad. Takes one of the following values:{“RHS", "Top"}
* __adwordsClickInfo.gclId__: The Google Click ID.
* __adwordsClickInfo.adNetworkType__: Network Type. Takes one of the following values: {“Google Search", "Content", "Search partners", "Ad Exchange", "Yahoo Japan Search", "Yahoo Japan AFS", “unknown”}
* __adwordsClickInfo.isVideoAd__: True if it is a Trueview video ad.




### Transaction Revenue 
As we have observed earlier, roughly 98% of this feature is missing. We can interpret these "missing values" as non-revenue. Hence, we will substitute NA with the value 0. 
```{r, message = FALSE, warning = FALSE}
train_TR_na <- is.na(train_set$transactionRevenue)
train_set$transactionRevenue[train_TR_na] <- 0
train_set$USD[train_TR_na] <- 0

test_TR_na <- is.na(test_set$transactionRevenue)
test_set$transactionRevenue[test_TR_na] <- 0
test_set$USD[test_TR_na] <- 0
```


```{r, message = FALSE, warning = FALSE}
revenue_positive <- which(train_set$transactionRevenue != 0)
paste0("Among the ", nrow(train_set), " sessions in the training set, ", length(revenue_positive), " of them had revenues.")   
summary(train_set$transactionRevenue[revenue_positive] / 10^6)
```
We can see that the max is much higher than the 3rd quartile. We can suspect that few sessions had extremely high transaction revenues. 


```{r, message = FALSE, warning = FALSE, fig.height = 2, fig.width = 10, echo=FALSE}
plot1 <- train_set %>% filter(USD > 0 & USD < 500) %>% 
  ggplot(aes(x=transactionRevenue/10^6)) + 
  geom_histogram(colour = "#1F3552", fill = "#4271AE", binwidth=10, alpha=0.3) +
  scale_y_continuous(labels = comma) +
  labs(x="", y="Sessions") +
  ggtitle("Transaction Revenues in USD($)", subtitle="Division by 1 million, excluding sessions without revenues") +
  theme_bw() 

plot2 <- train_set %>% filter(transactionRevenue > 0) %>% 
  ggplot(aes(x=log(transactionRevenue))) + 
  geom_histogram(colour = "#1F3552", fill = "#4271AE", alpha=0.3) +
  scale_y_continuous(labels = comma) +
  labs(x="", y="Sessions") +
  ggtitle("Transaction Revenues in USD($)", subtitle="Log transformation, excluding sessions without revenues") +
  theme_bw()

grid.arrange(plot1, plot2, nrow=1)
```
When the original values are divided by a million to make them in USD, plot is right skewed and centered around $50. But the plot of log transformed values seems quite normally distributed, and it is centered around 17.5. 

```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(plot1, plot2, test_TR_na, train_TR_na)
```





### Channels
```{r, message = FALSE, warning = FALSE}
paste0("There are ", length(unique(train_set$channelGrouping)), " different channels in the dataset. Among the channels, ", length(unique(train_set$channelGrouping[revenue_positive])), " channels were related to transactions")
```

```{r, message = FALSE, warning = FALSE, fig.height = 5, fig.width = 4.5, echo=FALSE}
channelGrouping_freq <- train_set %>% group_by(channelGrouping) %>% summarise(counts=n()) %>% arrange(counts)
ggplot(channelGrouping_freq, aes(x = reorder(channelGrouping, -counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Sessions By Channels", subtitle="Including sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```


```{r, message = FALSE, warning = FALSE, echo=FALSE}
train_set %>% group_by(channelGrouping) %>% summarise(Count=n(), Percentage=n()/nrow(train_set) * 100, TotRev = sum(transactionRevenue)/10^6, AveRev=mean(transactionRevenue)/10^6) %>% arrange(desc(Count)) %>% head(10)
```



```{r, message = FALSE, warning = FALSE, fig.height = 5, fig.width = 6, echo=FALSE}
RP_channelGrouping_freq <- train_set[revenue_positive, ] %>% group_by(channelGrouping) %>% summarise(counts=n(), TotRev = sum(transactionRevenue)/10^6) %>% arrange(desc(counts))
ggplot(RP_channelGrouping_freq, aes(x = reorder(channelGrouping, -counts))) +
  geom_col(aes(y = counts, fill="#0073C2FF"), alpha=0.4) +
  geom_text(aes(y = counts, label = counts), fontface = "bold", vjust = 1.4, color = "black", size = 3) +
  geom_line(aes(y = TotRev / 120, group = 1, color = "#000066"), linetype = "longdash", size=0.5) +
  geom_text(aes(y = TotRev / 120, label = paste0("$",round(TotRev, 0))), vjust = -1, color = "black", size = 3) +
  labs(x="", y="") +
  ggtitle("Transaction Revenues & Sessions By Channels", subtitle="Excluding sessions without revenues") +
  scale_y_continuous(labels = comma, sec.axis = sec_axis(trans = ~ . * 120, labels = comma)) +
  scale_fill_manual('', labels = 'Sessions', values = "#0073C2FF") +
  scale_color_manual('', labels = 'Transaction Revenues (USD)', values = 'black') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = c(.95, .95),
        legend.justification = c("right", "top"), legend.box.just = "right", legend.margin = margin(3, 3, 3, 3))

```


```{r, message = FALSE, warning = FALSE, echo=FALSE}
train_set[revenue_positive, ] %>% group_by(channelGrouping) %>% summarise(Count=n(), Percentage=n()/length(revenue_positive) * 100, TotRev = sum(transactionRevenue)/10^6, AveRev=mean(transactionRevenue)/10^6) %>% arrange(desc(Count)) %>% head(10) 
```
The two tables tell us that the proportion of same channels differ based on whether they are from the original dataset or dataset which contains only positive transanction revenues. For instance, in the new dataset, "Other" category has 0%, significantly lower percentage of "Affiliates" and "Social", etc.

```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(plot1, plot2, channelGrouping_freq, RP_channelGrouping_freq)
```





### Date
```{r, message = FALSE, warning = FALSE}
paste0("The date ranges from ", min(train_set$date), " to ", max(train_set$date))
```

Now, we will get days, weekdays, months, years from the "date"
```{r, message = FALSE, warning = FALSE}
train_set$day <- day(train_set$date)
test_set$day <- day(test_set$date)

train_set$DayoftheWeek <- wday(train_set$date, label = TRUE, abbr = FALSE)
test_set$DayoftheWeek <- wday(test_set$date, label = TRUE, abbr = FALSE)

train_set$month <- month(train_set$date, label=TRUE, abbr = FALSE)
test_set$month <- month(test_set$date, label=TRUE, abbr = FALSE)

train_set$year <- year(train_set$date)
test_set$year <- year(test_set$date)
```


```{r, message = FALSE, warning = FALSE, fig.height = 4.6, fig.width = 6, echo=FALSE}
date_freq <- train_set %>% group_by(date) %>% summarise(counts=n())
ggplot(date_freq, aes(x = date, y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.5) + 
  labs(x="", y="Sessions") +
  ggtitle("Sessions by Date", subtitle="Including sessions without revenues") +
  scale_y_continuous(labels = comma) +
  scale_x_date(date_labels = "%b %d %Y", date_breaks = "1 month") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```


```{r, message = FALSE, warning = FALSE, fig.height = 4.6, fig.width = 6, echo=FALSE}
RP_date_freq <- train_set[revenue_positive, ] %>% group_by(date) %>% summarise(counts=n())
ggplot(RP_date_freq, aes(x = date, y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.5) + 
  labs(x="", y="Sessions") +
  ggtitle("Sessions by Date", subtitle="Excluding sessions without revenues") +
  scale_y_continuous(labels = comma) +
  scale_x_date(date_labels = "%b %d %Y", date_breaks = "1 month") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```



```{r, message = FALSE, warning = FALSE, fig.height = 4.6, fig.width = 6, echo=FALSE}
RP_date_TR <- aggregate(train_set$transactionRevenue / (10^6), by=list(date=train_set$date), FUN=sum)
ggplot(RP_date_TR, aes(x = date, y = x)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.5) + 
  labs(x="", y="Total Revenues in USD ($)") +
  ggtitle("Transaction Revenues By Date") +
  scale_y_continuous(labels = comma) +
  scale_x_date(date_labels = "%b %d %Y", date_breaks = "1 month") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```




```{r, message = FALSE, warning = FALSE, fig.height = 7, fig.width = 10, echo=FALSE}
weekday <- train_set[revenue_positive, ] %>% group_by(DayoftheWeek) %>% summarise(counts=n(), percentage=n()/length(revenue_positive), TotRev = sum(transactionRevenue)/10^6 , AveRev=mean(transactionRevenue)/10^6) 

ggplot(weekday, aes(x = DayoftheWeek)) +
  geom_col(aes(y = counts, fill="#0073C2FF"), alpha=0.4) +
  geom_text(aes(y = counts, label = counts), fontface = "bold", vjust = 2, color = "black", size = 3) +
  geom_line(aes(y = TotRev / 85, group = 1, color = "#000066"), linetype = "longdash", size=0.5) +
  geom_text(aes(y = TotRev / 85, label = paste0("$",round(TotRev, 0))), vjust = -0.5, color = "black", size = 3) +
  labs(x="", y="") +
  ggtitle("Transaction Revenues & Sessions By Weekday") +
  scale_y_continuous(labels = comma, sec.axis = sec_axis(trans = ~ . * 85, labels = comma)) +
  scale_fill_manual('', labels = 'Sessions', values = "#0073C2FF") +
  scale_color_manual('', labels = 'Transaction Revenues (USD)', values = 'black') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = c(.95, .95),
        legend.justification = c("right", "top"), legend.box.just = "right", legend.margin = margin(6, 6, 6, 6))

```
Generally, we might assume that people will go online shopping on weekends more often than weekdays. However, this plot shows us that the weekends are as low as only half of weekdays. We can infer that, since GStore sells mostly company-related products, transactions are occurred during business hours on weekdays. 




```{r, message = FALSE, warning = FALSE, fig.height = 7, fig.width = 10, echo=FALSE}
by_month <- train_set[revenue_positive, ] %>% group_by(month=floor_date(date, "month")) %>% summarise(counts=n(), percentage=n()/length(revenue_positive), TotRev = sum(transactionRevenue)/10^6 , AveRev=mean(transactionRevenue)/10^6) 
abbreviate_month <- c("Aug 2016", "Sep 2016", "Oct 2016", "Nov 2016", "Dec 2016", "Jan 2017", "Feb 2017", "Mar 2017", "Apr 2017", "May 2017", "Jun 2017", "Jul 2017", "Aug 2017")
by_month[1] <- abbreviate_month
by_month$month <- factor(by_month$month, levels=abbreviate_month)

ggplot(by_month, aes(x = month)) +
  geom_col(aes(y = counts, fill="#0073C2FF"), alpha=0.4) +
  geom_text(aes(y = counts, label = counts), fontface = "bold", vjust = -1, color = "black", size = 3) +
  geom_line(aes(y = TotRev / 180, group = 1, color = "#000066"), linetype = "longdash", size=0.5) +
  geom_text(aes(y = TotRev / 180, label = paste0("$",round(TotRev, 0))), vjust = 0.5, color = "black", size = 3) +
  labs(x="", y="") +
  ggtitle("Transaction Revenues & Sessions By Month") +
  scale_y_continuous(labels = comma, sec.axis = sec_axis(trans = ~ . * 180, labels = comma)) +
  scale_fill_manual('', labels = 'Sessions', values = "#0073C2FF") +
  scale_color_manual('', labels = 'Transaction Revenues (USD)', values = 'black') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = c(1, 1),
        legend.justification = c("right", "top"), legend.box.just = "right", legend.margin = margin(6, 6, 6, 6))


```

Interestingly, there was the highest transaction revenues in April 2017, even though the month has only the 5th highest number of sessions. We can suspect that the outliers from the transactionRevenue belong to the month. 

```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(date_freq, RP_date_freq, RP_date_TR, weekday, by_month, abbreviate_month)
```






### ID
There are three types of ID's in this dataset: fullVisitorId, visitId, and sessionId

```{r, message = FALSE, warning = FALSE}
head(train_set$fullVisitorId, 5)
head(train_set$visitId, 5)   
head(train_set$sessionId, 5)         
```
We can see that sessionId is a combination of fullVisitorId and visitId. 



```{r, message = FALSE, warning = FALSE}
dup_sessionId <- which(duplicated(GA_combined$sessionId)==TRUE)
paste0(length(unique(GA_combined$sessionId)), " entries from sessionId are unique id's")
```

And, 878 (=903653-902755) session ID's are duplicated. Since sessionId should be a unique number, we will look into this more closely. Let's take the first entry from the "dup_sessionid". It's the 50182nd row from the "GA_combined". We will figure out which other rows have the same session ID and see how their entire data look like. 

```{r, message = FALSE, warning = FALSE}
dup_example <- GA_combined$sessionId[50182]
dup_example_rows <- which(GA_combined$sessionId==dup_example)
GA_combined[dup_example_rows, ]
```
As you can see, some of features from each session ID such as visitStartTime, hits, and pageViews have different values. So we can conclude that the rows with duplicated sessionId's are not necessarily duplicated. Hence, we will keep the rows. 








### Visit Start Time
```{r, message = FALSE, warning = FALSE}
head(train_set$visitStartTime, 20)

```
We can see that visitStartTime is the same as visitId. 

```{r, message = FALSE, warning = FALSE}
train_vst <- as_datetime(train_set$visitStartTime)
head(train_vst, 20)
rm(train_vst)
```
If we convert the feature to POSIXct format, we can see that they are UTC timestamp regardless of their  regions. Also, we have almost the same data in "date" feature. Hence, we will drop this feature. 


```{r, message = FALSE, warning = FALSE}
train_set$visitStartTime <- NULL
test_set$visitStartTime <- NULL
```

```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(dup_example, dup_example_rows, dup_sessionId)
```





### Browser
```{r, message = FALSE, warning = FALSE}
paste0("There are ", length(unique(train_set$browser)), " different browsers in the dataset. Among the browsers, ", length(unique(train_set$browser[revenue_positive])), " browsers were related to transactions")
```

```{r, message = FALSE, warning = FALSE, fig.height = 7, fig.width = 10, echo=FALSE}
browser_freq <- train_set %>% group_by(browser) %>% summarise(counts=n()) %>% arrange(desc(counts)) %>% head(10)
ggplot(browser_freq, aes(x = reorder(browser, -counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Sessions By Browsers", subtitle="Including sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```

```{r, message = FALSE, warning = FALSE}
train_set %>% group_by(browser) %>% summarise(Count=n(), Percentage=n()/nrow(train_set) * 100, TotRev = sum(transactionRevenue)/10^6, AveRev=mean(transactionRevenue)/10^6) %>% arrange(desc(Count)) %>% head(10)
```



```{r, message = FALSE, warning = FALSE, fig.height = 7, fig.width = 10, echo=FALSE}
RP_browser <- train_set[revenue_positive, ] %>% group_by(browser) %>% summarise(Count=n(), Percentage=n()/length(revenue_positive) * 100, TotRev = sum(transactionRevenue)/10^6, AveRev=mean(transactionRevenue)/10^6) %>% arrange(desc(Count)) %>% head(10) 


ggplot(RP_browser, aes(x = reorder(browser, -Count))) +
  geom_col(aes(y = Count, fill="#0073C2FF"), alpha=0.4) +
geom_text(aes(y = Count, label = Count), fontface = "bold", vjust = 1.4, color = "black", size = 3) +
  geom_line(aes(y = TotRev / 135, group = 1, color = "#000066"), linetype = "longdash", size=0.5) +
  geom_text(aes(y = TotRev / 135, label = paste0("$",round(TotRev, 0))), vjust = -1, color = "black", size = 3) +
  labs(x="", y="") +
  ggtitle("Transaction Revenues & Sessions By Browsers") +
  scale_y_continuous(labels = comma, sec.axis = sec_axis(trans = ~ . * 135, labels = comma)) +
  scale_fill_manual('', labels = 'Sessions', values = "#0073C2FF") +
  scale_color_manual('', labels = 'Transaction Revenues (USD)', values = 'black') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = c(.95, .95),
        legend.justification = c("right", "top"), legend.box.just = "right", legend.margin = margin(6, 6, 6, 6))

```

```{r, message = FALSE, warning = FALSE}
RP_browser
```
The first table includes all the entries including the ones with non-zero revenues, whereas the second table contains only sessions with positive revenues. The two tables tell us that the order of the 5 most frequent browsers remain the same, but the order of the rest browsers change a bit. 

We can observe that the total transaction revenue from second highest browser, Safari, is actually almost half of the total transaction revenue from Firefox. 

```{r, message = FALSE, warning = FALSE, echo = FALSE}
rm(RP_browser, browser_freq)
```




### Operating System

```{r, message = FALSE, warning = FALSE}
paste0("There are ", length(unique(train_set$operatingSystem)), " different operating systems in the dataset. Among the operating systems, ", length(unique(train_set$operatingSystem[revenue_positive])), " operating systems were related to transactions")
```

```{r, message = FALSE, warning = FALSE, fig.height = 7, fig.width = 10, echo=FALSE}
operatingSystem_freq <- train_set %>% group_by(operatingSystem) %>% summarise(counts=n()) %>% arrange(desc(counts)) %>% head(10)
ggplot(operatingSystem_freq, aes(x = reorder(operatingSystem, -counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Sessions By Operating Systems", subtitle="Including sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```

```{r, message = FALSE, warning = FALSE}
train_set %>% group_by(operatingSystem) %>% summarise(Count=n(), Percentage=n()/nrow(train_set) * 100, TotRev = sum(transactionRevenue)/10^6, AveRev=mean(transactionRevenue)/10^6) %>% arrange(desc(Count)) %>% head(10)
```

```{r, message = FALSE, warning = FALSE, fig.height = 7, fig.width = 10, echo=FALSE}
RP_operatingSystem <- train_set[revenue_positive, ] %>% group_by(operatingSystem) %>% summarise(Count=n(), Percentage=n()/length(revenue_positive) * 100, TotRev = sum(transactionRevenue)/10^6, AveRev=mean(transactionRevenue)/10^6) %>% arrange(desc(Count)) %>% head(10) 

ggplot(RP_operatingSystem, aes(x = reorder(operatingSystem, -Count))) +
  geom_col(aes(y = Count, fill="#0073C2FF"), alpha=0.4) +
  geom_text(aes(y = Count, label = Count), fontface = "bold", vjust = 1.8, color = "black", size = 3) +
  geom_line(aes(y = TotRev / 133, group = 1, color = "#000066"), linetype = "longdash", size=0.5) +
  geom_text(aes(y = TotRev / 133, label = paste0("$",round(TotRev, 0))), vjust = -1.1, color = "black", size = 3) +
  labs(x="", y="") +
  ggtitle("Transaction Revenues & Sessions By Operating Systems") +
  scale_y_continuous(labels = comma, sec.axis = sec_axis(trans = ~ . * 133, labels = comma)) +
  scale_fill_manual('', labels = 'Sessions', values = "#0073C2FF") +
  scale_color_manual('', labels = 'Transaction Revenues (USD)', values = 'black') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = c(.95, .95),
        legend.justification = c("right", "top"), legend.box.just = "right", legend.margin = margin(6, 6, 6, 6))
```

```{r, message = FALSE, warning = FALSE}
RP_operatingSystem
```

The first table includes all the entries including the ones with non-zero revenues, whereas the second table contains only sessions with positive revenues. Windows and Macintosh from the first table has the first and second highest frequency, respectively, out of 19 operating systems. However, it is the most frequent session in the second table, recording almost 3x higher sessions than Windows. 


```{r, message = FALSE, warning = FALSE, echo = FALSE}
rm(RP_operatingSystem, operatingSystem_freq)
```






### Device Category
In this section, we will try to figure out whether device categories produce a recognizable difference in terms of transaction revenues. 

```{r, message = FALSE, warning = FALSE}
paste0("There are ", length(unique(train_set$deviceCategory)), " different device categories in the dataset. Among the device categories, ", 
       length(unique(train_set$deviceCategory[revenue_positive])), " device categories were related to transactions")
```
```{r, message = FALSE, warning = FALSE, fig.height = 6, fig.width = 10, echo=FALSE}
deviceCatgeory_freq <- train_set %>% group_by(deviceCategory) %>% summarise(counts=n()) %>% arrange(counts)
plot1 <- ggplot(deviceCatgeory_freq, aes(x = reorder(deviceCategory, -counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Devices", subtitle="Including sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme_minimal()

RP_deviceCatgeory_freq <- train_set[revenue_positive, ] %>% group_by(deviceCategory) %>% summarise(counts=n(), TotRev = sum(transactionRevenue)/10^6) %>% arrange(desc(counts))

plot2 <- ggplot(RP_deviceCatgeory_freq, aes(x = reorder(deviceCategory, -counts))) +
  geom_col(aes(y = counts, fill="#0073C2FF"), alpha=0.4) +
  geom_text(aes(y = counts, label = counts), fontface = "bold", vjust = 2.3, color = "black", size = 3) +
  geom_line(aes(y = TotRev / 120, group = 1, color = "#000066"), linetype = "longdash", size=0.5) +
  geom_text(aes(y = TotRev / 120, label = paste0("$",round(TotRev, 0))), vjust = -1, color = "black", size = 3) +
  labs(x="", y="") +
  ggtitle("Transaction Revenues & Sessions By Devices") +
  scale_y_continuous(labels = comma, sec.axis = sec_axis(trans = ~ . * 120, labels = comma)) +
  scale_fill_manual('', labels = 'Sessions', values = "#0073C2FF") +
  scale_color_manual('', labels = 'Transaction Revenues (USD)', values = 'black') +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = c(.95, .95),
        legend.justification = c("right", "top"), legend.box.just = "right", legend.margin = margin(6, 6, 6, 6))

grid.arrange(plot1, plot2, nrow=1)

```

```{r, message = FALSE, warning = FALSE}
train_set %>% group_by(deviceCategory) %>% summarise(Count=n(), Percentage=n()/nrow(train_set) * 100, TotRev = sum(transactionRevenue)/10^6, AveRev=mean(transactionRevenue)/10^6) %>% arrange(desc(Count)) %>% head(10)
```

```{r, message = FALSE, warning = FALSE}
train_set[revenue_positive, ] %>% group_by(deviceCategory) %>% summarise(Count=n(), Percentage=n()/length(revenue_positive) * 100, TotRev = sum(transactionRevenue)/10^6, AveRev=mean(transactionRevenue)/10^6) %>% arrange(desc(Count)) %>% head(10) 
```


```{r, message = FALSE, warning = FALSE, fig.height =4, fig.width = 10, echo=FALSE}
train_set %>% filter(transactionRevenue/(10^6) > 0 & transactionRevenue/(10^6) < 500) %>% 
  ggplot(aes(x=transactionRevenue/10^6, color=deviceCategory)) +
  geom_density(size=1)+
  labs(title="Transaction Revenues by Device Category",x="USD($)", y = "Density", subtitle="Division by 1 million, excluding sessions without revenues") +
  scale_color_brewer(palette="Dark2") + 
  theme_minimal() 

```
This feature basically contains all the information that the feature 'isMobile' provides (isMobile is comprised of logical values, true or false. If a user accesses with a mobile device such as mobile phone or tablet, the value is true, and vice versa.) 

```{r, message = FALSE, warning = FALSE}
table(train_set$isMobile, useNA = 'ifany') / nrow(train_set)
```

```{r, message = FALSE, warning = FALSE}
table(train_set$isMobile[revenue_positive], useNA = 'ifany') / length(revenue_positive)
```

So we will drop 'isMobile' to make our model less complicated. 
```{r, message = FALSE, warning = FALSE}
train_set$isMobile <- NULL
test_set$isMobile <- NULL
```


```{r, message = FALSE, warning = FALSE, echo = FALSE}
rm(plot1, plot2, RP_deviceCatgeory_freq, deviceCatgeory_freq)
```





### Continent
```{r, message = FALSE, warning = FALSE}
paste0("There are ", length(unique(train_set$continent)), " different continents in the dataset. Among the continents, there were transactions in ", length(unique(train_set$continent[revenue_positive])), " continents")
```


```{r, message = FALSE, warning = FALSE, fig.height = 4.5, fig.width = 10, echo=FALSE}
continent_freq <- train_set %>% group_by(continent) %>% summarise(counts=n()) %>% arrange(desc(counts)) %>% head(10)
plot1 <- ggplot(continent_freq, aes(x = reorder(continent, counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Sessions By Continents", subtitle="Including sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  coord_flip()

PR_continent_freq <- train_set[revenue_positive, ] %>% group_by(continent) %>% summarise(counts=n()) %>% arrange(desc(counts)) %>% head(10)
plot2 <- ggplot(PR_continent_freq, aes(x = reorder(continent, counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Sessions By Continents", subtitle="Excluding sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  coord_flip()

grid.arrange(plot1, plot2, nrow=1)
```

While other continents than America have accessed to the site quite many times, the number of sessions that had actual transactions is almost negligible. For example, there were 167702 sessions in Asia, but only 0.05% (=90/167702) of them had revenues. 

```{r, message = FALSE, warning = FALSE, echo=FALSE}
train_set[revenue_positive, ] %>% group_by(continent) %>% summarise(Count=n(), Percentage=n()/length(revenue_positive) * 100, TotRev = sum(transactionRevenue)/10^6, AveRev=mean(transactionRevenue)/10^6) %>% arrange(desc(Count)) %>% head(10) 
```


```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(plot1, plot2, PR_continent_freq, continent_freq)
```







### Country

```{r, message = FALSE, warning = FALSE, fig.height = 4.5, fig.width = 10, echo=FALSE}
country_freq <- train_set %>% group_by(country) %>% summarise(counts=n()) %>% arrange(desc(counts)) %>% head(10)
plot1 <- ggplot(country_freq, aes(x = reorder(country, counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Sessions By Countries", subtitle="Including sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  coord_flip()

PR_country_freq <- train_set[revenue_positive, ] %>% group_by(country) %>% summarise(counts=n()) %>% arrange(desc(counts)) %>% head(10)
plot2 <- ggplot(PR_country_freq, aes(x = reorder(country, counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Sessions By Countries", subtitle="Excluding sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  coord_flip()

grid.arrange(plot1, plot2, nrow=1)
```

The two plots above tell us that India has the second highest sessions out of 221 countries. However, the country does not generate expenses. 

```{r, message = FALSE, warning = FALSE}
train_set[revenue_positive, ] %>% group_by(country) %>% summarise(Count=n(), Percentage=n()/length(revenue_positive), AveRev=mean(transactionRevenue)/10^6) %>% arrange(desc(Percentage)) %>% head(10)
```

```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(plot1, plot2, PR_country_freq, country_freq)
```






### Hits

```{r, message = FALSE, warning = FALSE, fig.height = 4.5, fig.width = 10, echo=FALSE}
plot1 <- train_set %>% filter(hits < 25) %>% 
  ggplot(aes(x=hits)) + 
  geom_histogram(colour = "#1F3552", fill = "#4271AE", binwidth=1, alpha=0.3) +
  scale_x_continuous(breaks=seq(0, 25, by=5)) +
  scale_y_continuous(breaks=seq(0, 400000, by=100000), labels = comma) +
  labs(x="", y="Sessions") +
  ggtitle("Sessions by Hits", subtitle="Including sessions without revenues") +
  theme_bw() 

plot2 <- train_set %>% filter(transactionRevenue > 0 & hits < 100) %>% 
  ggplot(aes(x=hits)) + 
  geom_histogram(colour = "#1F3552", fill = "#4271AE", binwidth=2, alpha=0.3) +
  scale_x_continuous(breaks=seq(0, 100, by=5)) +
  scale_y_continuous(breaks=seq(0, 1000, by=100), labels = comma) +
  labs(x="", y="Sessions") +
  ggtitle("Sessions by Hits", subtitle="Excluding sessions without revenues") +
  theme_bw() 

grid.arrange(plot1, plot2, nrow=1)
```
As you can see the plots above, they are right skewed. However, the degrees of skewness are different. Among the sessions that had transaction revenues, the hit==15 has the most sessions.  And the number of sessions drops slowly when the "hit" increases. 

```{r, message = FALSE, warning = FALSE, fig.height = 4.5, fig.width = 10, echo=FALSE}
train_set %>% filter(transactionRevenue > 0 & hits < 100) %>%
  ggplot(aes(x=hits, y=transactionRevenue/10^6)) +
  geom_smooth(method='loess') +
  labs(x="Hits", y="Transaction Revenues in USD($)") +
  ggtitle("Transaction Revenues by Hits", subtitle="Loess Smoothed Fit Curve") +
  theme_bw() 
```
This plot that tells us that as the feature "hits" goes up, the transaction revenue also increases. The higher hit indicates that a user is interacting with the website more. So, it means that they are intereseted in the products.

```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(plot1, plot2)
```






## Page Views
First, we will substitue NA with 0 

```{r, message = FALSE, warning = FALSE}
pageviews_na_train <- which(is.na(train_set$pageviews==TRUE))
pageviews_na_test <- which(is.na(test_set$pageviews==TRUE))

train_set$pageviews[pageviews_na_train] <- 0
test_set$pageviews[pageviews_na_test] <- 0
```



```{r, message = FALSE, warning = FALSE, fig.height = 4.5, fig.width = 10, echo=FALSE}
plot1 <- train_set %>% filter(pageviews < 25 & is.na(pageviews) == FALSE) %>%  
  ggplot(aes(x=pageviews)) + 
  geom_histogram(colour = "#1F3552", fill = "#4271AE", binwidth=1, alpha=0.3) +
  scale_x_continuous(breaks=seq(0, 25, by=5)) +
  scale_y_continuous(breaks=seq(0, 400000, by=100000), labels = comma) +
  labs(x="", y="Sessions") +
  ggtitle("Sessions by Page Views", subtitle="Including sessions without revenues") +
  theme_bw() 

plot2 <- train_set %>% filter(transactionRevenue > 0 & pageviews < 100 & is.na(pageviews) == FALSE) %>% 
  ggplot(aes(x=pageviews)) + 
  geom_histogram(colour = "#1F3552", fill = "#4271AE", binwidth=2, alpha=0.3) +
  scale_x_continuous(breaks=seq(0, 100, by=5)) +
  scale_y_continuous(breaks=seq(0, 1000, by=100), labels = comma) +
  labs(x="", y="Sessions") +
  ggtitle("Sessions by Page Views", subtitle="Excluding sessions without revenues") +
  theme_bw() 

grid.arrange(plot1, plot2, nrow=1)
```


```{r, message = FALSE, warning = FALSE, fig.height = 4.5, fig.width = 10, echo=FALSE}
train_set %>% filter(transactionRevenue > 0 & pageviews < 100 & is.na(pageviews) == FALSE) %>%
  ggplot(aes(x=pageviews, y=transactionRevenue/10^6)) +
  geom_smooth(method='loess') +
  labs(x="Page Views", y="Transaction Revenues in USD($)") +
  ggtitle("Transaction Revenues by Page Views", subtitle="Loess Smoothed Fit Curve") +
  theme_bw() 
```
We can see that this feature is showing similar patterns as that of "hits". We can observe that the two features, hits and pageviews, not only have a very similar distribution, but also almost identical loess smoothed fit curves. The correlation between the two is approximately 0.98 which is very high. 
```{r, message = FALSE, warning = FALSE}
cor(train_set$hits[revenue_positive], train_set$pageviews[revenue_positive])
```

```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(plot1, plot2, pageviews_na_train, pageviews_na_test)
```







### Bounce
We will substitute NA with 0. 
```{r, message = FALSE, warning = FALSE}
train_bounces_na <- is.na(train_set$bounces)
train_set$bounces[train_bounces_na] <- 0
test_bounces_na <- is.na(test_set$bounces)
test_set$bounces[test_bounces_na] <- 0
```

Since bounce means 1-pageview, the features pageviews==1 and bounces==1 should have equal number of sessions. However, as the following two tables show, the numbers don't match. 
```{r, message = FALSE, warning = FALSE}
bounce1 <- train_set[train_set$bounces==1, ] %>% nrow()     
pageview1 <- train_set[train_set$pageviews==1, ] %>% nrow()
paste0("The total number that website users bounced: ", bounce1, " / The total number of 1-pageview: ", pageview1)
```

The number of sessions that have both bounces==1 and pageviews==1 is as follows. 
```{r, message = FALSE, warning = FALSE}
which(train_set$bounces==1 & train_set$pageviews==1) %>% length()
```

We will convert some of data in "bounces" to 1 if the corresponding row has pageviews==1
```{r, message = FALSE, warning = FALSE}
train_set$bounces[which(train_set$pageviews==1)] <- 1
```

And, of course, it cannot have transaction revenues when bounce==1 or pageviews==1 because it takes at least two pages to purchase something online.
```{r, message = FALSE, warning = FALSE}
train_set[train_set$trasactionRevenue >0 & train_set$bounces==1, ] %>% nrow()
train_set[train_set$trasactionRevenue >0 & train_set$pageviews==1, ] %>% nrow()
```

We will figure out how many sessions bounced or did not bounce, and how many of them had transactions. 

```{r, message = FALSE, warning = FALSE, fig.height = 4, fig.width = 10, echo=FALSE}
bounces_freq <- train_set %>% group_by(bounces) %>% summarise(counts=n()) %>% arrange(counts)
plot1 <- ggplot(bounces_freq, aes(x = bounces, y = counts, fill=bounces)) +
  geom_bar(stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  scale_fill_brewer(palette="Paired", name = "New Visit", labels = c("No", "Yes")) +
  ggtitle("Bounces", subtitle="Including sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_bw() 


PR_bounces_freq <- train_set[revenue_positive, ] %>% group_by(bounces) %>% summarise(counts=n()) %>% arrange(counts)
plot2 <- ggplot(PR_bounces_freq, aes(x = bounces, y = counts, fill=bounces)) +
  geom_bar(stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  scale_fill_brewer(palette="Paired", name = "New Visit", labels = c("No", "Yes")) +
  ggtitle("Bounces", subtitle="Excluding sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_bw() 

grid.arrange(plot1, plot2, nrow=1)
```

* Purchase rate of a session that bounced:  0% (=0/339518)
* Purchase rate of a session that did not bounced: 2.53% (=8570/338221)




```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(train_bounces_na, test_bounces_na, bounce1, pageview1, PR_bounces_freq, bounces_freq)
```





### newVisits
We will substitute NA with 0.
```{r, message = FALSE, warning = FALSE}
train_newVisits_na <- is.na(train_set$newVisits)
train_set$newVisits[train_newVisits_na] <- 0
test_newVisits_na <- is.na(test_set$newVisits)
test_set$newVisits[test_newVisits_na] <- 0
```



We will figure out how many users are first time visitors or returning visitors, and how many of the visitors purchased something. 

```{r, message = FALSE, warning = FALSE, fig.height = 4, fig.width = 10, echo=FALSE}
newVisits_freq <- train_set %>% group_by(newVisits) %>% summarise(counts=n()) %>% arrange(counts)
plot1 <- ggplot(newVisits_freq, aes(x = newVisits, y = counts, fill=newVisits)) +
  geom_bar(stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  scale_fill_brewer(palette="Paired", name = "New Visit", labels = c("No", "Yes")) +
  ggtitle("New Visits", subtitle="Including sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_bw() 


PR_newVisits_freq <- train_set[revenue_positive, ] %>% group_by(newVisits) %>% summarise(counts=n()) %>% arrange(counts)
plot2 <- ggplot(PR_newVisits_freq, aes(x = newVisits, y = counts, fill=newVisits)) +
  geom_bar(stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  scale_fill_brewer(palette="Paired", name = "New Visit", labels = c("No", "Yes")) +
  ggtitle("New Visits", subtitle="Excluding sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_bw() 

grid.arrange(plot1, plot2, nrow=1)
```

* Purchase rate of a returning visitor:  3.44% (=5183/150695)
* Purchase rate of a first time visitor: 0.64% (=3387/527044)



```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(newVisits_freq, PR_newVisits_freq, train_newVisits_na, test_newVisits_na, plot1, plot2)
```







### Source & Medium
We are given two separate features; source and medium. 

```{r, message = FALSE, warning = FALSE, fig.height = 4.5, fig.width = 10, echo=FALSE}
source_freq <- train_set %>% group_by(source) %>% summarise(counts=n()) %>% arrange(desc(counts)) %>% head(10)
plot1 <- ggplot(source_freq, aes(x = reorder(source, counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Sessions By Sources", subtitle="Including sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  coord_flip()

PR_source_freq <- train_set[revenue_positive, ] %>% group_by(source) %>% summarise(counts=n()) %>% arrange(desc(counts)) %>% head(10)
plot2 <- ggplot(PR_source_freq, aes(x = reorder(source, counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Sessions By Sources", subtitle="Excluding sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  coord_flip()

grid.arrange(plot1, plot2, nrow=1)
```

```{r, message = FALSE, warning = FALSE}
train_set[revenue_positive, ] %>% group_by(source) %>% summarise(Count=n(), Percentage=n()/length(revenue_positive), AveRev=mean(transactionRevenue)/10^6) %>% arrange(desc(Percentage)) %>% head(10)
```

We can see that youtube.com has the second highest number of sessions, but interestingly, sessions from youtube did not even make top 10 of sessions that had transaction revenues.


```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(source_freq, PR_source_freq, plot1, plot2)
```


```{r, message = FALSE, warning = FALSE, fig.height = 4.5, fig.width = 10, echo=FALSE}
medium_freq <- train_set %>% group_by(medium) %>% summarise(counts=n()) %>% arrange(desc(counts)) 
plot1 <- ggplot(medium_freq, aes(x = reorder(medium, counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Sessions By Medium", subtitle="Including sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  coord_flip()

PR_medium_freq <- train_set[revenue_positive, ] %>% group_by(medium) %>% summarise(counts=n()) %>% arrange(desc(counts)) 
plot2 <- ggplot(PR_medium_freq, aes(x = reorder(medium, counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Sessions By Medium", subtitle="Excluding sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  coord_flip()

grid.arrange(plot1, plot2, nrow=1)
```

```{r, message = FALSE, warning = FALSE}
train_set[revenue_positive, ] %>% group_by(medium) %>% summarise(Count=n(), Percentage=n()/length(revenue_positive), AveRev=mean(transactionRevenue)/10^6) %>% arrange(desc(Percentage))
```

```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(medium_freq, PR_medium_freq, plot1, plot2)
```





### isTrueDirect
We will substitute NA with FALSE.
```{r, message = FALSE, warning = FALSE}
train_isTrueDirect_na <- is.na(train_set$isTrueDirect)
train_set$isTrueDirect[train_isTrueDirect_na] <- 0
test_isTrueDirect_na <- is.na(test_set$isTrueDirect)
test_set$isTrueDirect[test_isTrueDirect_na] <- 0
```

Convert this feature to a character variable temporarily to make a barplot
```{r, message = FALSE, warning = FALSE}
train_set %<>% mutate(isTrueDirect = as.character(isTrueDirect))
test_set %<>% mutate(isTrueDirect = as.character(isTrueDirect))
```

We will figure out how many users accessed the site directly, and how many of them purchased something. 

```{r, message = FALSE, warning = FALSE, fig.height = 4, fig.width = 10, echo=FALSE}
isTrueDirect_freq <- train_set %>% group_by(isTrueDirect) %>% summarise(counts=n()) %>% arrange(counts)
plot1 <- ggplot(isTrueDirect_freq, aes(x = isTrueDirect, y = counts, fill=isTrueDirect)) +
  geom_bar(stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  scale_fill_brewer(palette="Paired", name = "Direct", labels = c("No", "Yes")) +
  ggtitle("Direct Access", subtitle="Including sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_bw() 


PR_isTrueDirect_freq <- train_set[revenue_positive, ] %>% group_by(isTrueDirect) %>% summarise(counts=n()) %>% arrange(counts)
plot2 <- ggplot(PR_isTrueDirect_freq, aes(x = isTrueDirect, y = counts, fill=isTrueDirect)) +
  geom_bar(stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  scale_fill_brewer(palette="Paired", name = "Direct", labels = c("No", "Yes")) +
  ggtitle("Direct Access", subtitle="Excluding sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_bw() 

grid.arrange(plot1, plot2, nrow=1)
```

* Purchase rate of a visitor with direct access:  2.52% (=5173/205557)
* Purchase rate of a visitor with indirect access: 0.72% (=3397/472182)





```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(isTrueDirect_freq, PR_isTrueDirect_freq, train_isTrueDirect_na, test_isTrueDirect_na, plot1, plot2)
```





### Referral Paths

```{r, message = FALSE, warning = FALSE, fig.height = 4.5, fig.width = 10, echo=FALSE}
referralPath_freq <- train_set %>% group_by(referralPath) %>% summarise(counts=n()) %>% arrange(desc(counts)) %>% head(5)
plot1 <- ggplot(referralPath_freq, aes(x = reorder(referralPath, counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Sessions By Referral Paths", subtitle="Including sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  coord_flip()

PR_referralPath_freq <- train_set[revenue_positive, ] %>% group_by(referralPath) %>% summarise(counts=n()) %>% arrange(desc(counts)) %>% head(5)
plot2 <- ggplot(PR_referralPath_freq, aes(x = reorder(referralPath, counts), y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity", alpha=0.4) + 
  geom_text(aes(label = counts), vjust = -0.2) +
  labs(x="", y="") +
  ggtitle("Sessions By Referral Paths", subtitle="Excluding sessions without revenues") +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  coord_flip()

grid.arrange(plot1, plot2, nrow=1)
```


```{r, message = FALSE, warning = FALSE}
train_set[revenue_positive, ] %>% group_by(referralPath) %>% summarise(Count=n(), Percentage=n()/length(revenue_positive), AveRev=mean(transactionRevenue)/10^6) %>% arrange(desc(Percentage)) %>% head(10)
```


```{r, message = FALSE, warning = FALSE, echo=FALSE}
rm(referralPath_freq, PR_referralPath_freq, plot1, plot2)
```





# 4 Data Cleaning & Feature Engineering 
When predicting transaction revenues, user ID's are useless. So we are going to drop the following three features; "fullVisitorId", "sessionId", "visitId". Also, we'll keep the "DayoftheWeek", "day", "month", and "year" that were extracted from the "date", and drop the "date". Also, the "adwordsClickInfo.isVideoAd" is comprised of FALSE and <NA>. We will convert it to 0/1. And the "campaignCode" is useless because all but one row from the feature is NA.
```{r, message = FALSE, warning = FALSE}
train_set %<>% select(-fullVisitorId, -sessionId, -visitId, -date, -campaignCode, -USD) 
test_set %<>% select(-fullVisitorId, -sessionId, -visitId, -date, -campaignCode, -USD)

train_AD_na <- is.na(train_set$adwordsClickInfo.isVideoAd)
train_set$adwordsClickInfo.isVideoAd[train_AD_na] <- TRUE
test_AD_na <- is.na(test_set$adwordsClickInfo.isVideoAd)
test_set$adwordsClickInfo.isVideoAd[test_AD_na] <- TRUE
train_set %<>% mutate(adwordsClickInfo.isVideoAd = ifelse(adwordsClickInfo.isVideoAd, 1, 0))
test_set %<>% mutate(adwordsClickInfo.isVideoAd = ifelse(adwordsClickInfo.isVideoAd, 1, 0))

train_set %<>% mutate(transactionRevenue = log1p(transactionRevenue))
test_set %<>% mutate(transactionRevenue = log1p(transactionRevenue))
```


Convert character variables to factor variables and check which features are factor variables. 
```{r, message = FALSE, warning = FALSE}


train_set %<>% mutate_if(is.character, factor) %>% mutate(adwordsClickInfo.isVideoAd=factor(adwordsClickInfo.isVideoAd), day=factor(day), year=factor(year))

test_set %<>% mutate_if(is.character, factor) %>% mutate(adwordsClickInfo.isVideoAd=factor(adwordsClickInfo.isVideoAd), day=factor(day), year=factor(year))



factor_variables <- names(train_set)[sapply(train_set, class) == "factor"]
factor_variables
```


We will lump all the infrequent levels (less than 1%: approximately 6700 in train set) into one factor, "other". We will only keep "n" levels. 
```{r, message = FALSE, warning = FALSE}
train_set %<>% mutate(browser=fct_lump(browser, n=5), 
                      operatingSystem=fct_lump(operatingSystem, n=6), 
                      subContinent=fct_lump(subContinent, n=12), 
                      country=fct_lump(country, n=21), 
                      region=fct_lump(region, n=5), 
                      metro=fct_lump(metro, n=5), 
                      city=fct_lump(city, n=8),
                      networkDomain=fct_lump(networkDomain, n=6),
                      campaign=fct_lump(campaign, n=4),
                      source=fct_lump(source, n=6),
                      keyword=fct_lump(keyword, n=2),
                      referralPath=fct_lump(referralPath, n=10),
                      adContent=fct_lump(adContent, n=1),
                      adwordsClickInfo.page=fct_lump(adwordsClickInfo.page, n=2),
                      adwordsClickInfo.gclId=fct_lump(adwordsClickInfo.gclId, n=1))

test_set %<>% mutate(browser=fct_lump(browser, n=5), 
                      operatingSystem=fct_lump(operatingSystem, n=6), 
                      subContinent=fct_lump(subContinent, n=12), 
                      country=fct_lump(country, n=21), 
                      region=fct_lump(region, n=5), 
                      metro=fct_lump(metro, n=5), 
                      city=fct_lump(city, n=8),
                      networkDomain=fct_lump(networkDomain, n=6),
                      campaign=fct_lump(campaign, n=4),
                      source=fct_lump(source, n=6),
                      keyword=fct_lump(keyword, n=2),
                      referralPath=fct_lump(referralPath, n=10),
                      adContent=fct_lump(adContent, n=1),
                      adwordsClickInfo.page=fct_lump(adwordsClickInfo.page, n=2),
                      adwordsClickInfo.gclId=fct_lump(adwordsClickInfo.gclId, n=1))
```



Create matrix - One hot encoding for factor variables
```{r, message = FALSE, warning = FALSE}
options(na.action='na.pass')
train_OHE <- sparse.model.matrix(transactionRevenue ~.-1, data=train_set)
train_label <- train_set[, "transactionRevenue"]
train_matrix_xgb <- xgb.DMatrix(data=as.matrix(train_OHE), label=train_label)

test_OHE <- sparse.model.matrix(transactionRevenue ~.-1, data=test_set)
test_label <- test_set[, "transactionRevenue"]
test_matrix_xgb <- xgb.DMatrix(data=as.matrix(test_OHE), label=test_label)
```


# 5 Model Building



### XGBoost
The general process of using XGBoost is to first find the best parameter values and rnounds, and then use the values to build a model. One way to find the best parameter values would be using "train" function with the "expand.grid" function based on cross validation. However, due to the memory limitations and general performance of my computer, I am currently not able to perform the parameter tuning. Once I upgrade a machine, I will come back to this and try to tune the parameter values to increase the accuarcy of this model. So, we will use the default parameters except for the "nrounds". The best nrounds based on the other default parameters.  


```{r, message = FALSE, warning = FALSE}
#default parameters
param.xgb <- list(booster = "gbtree", objective = "reg:squarederror", eta=0.3, gamma=0, max_depth=6, min_child_weight=1, subsample=1, colsample_bytree=1)

xgb.crossval <- xgb.cv(params = param.xgb, data = train_matrix_xgb, nrounds = 100, nfold = 5, showsd = T, stratified = T, print.every.n = 10, early.stop.round = 20, maximize = F)

```

```{r, message = FALSE, warning = FALSE}
#model training using default parameters and evaluating with the test set
xgb.default <- xgb.train(params = param.xgb, data = train_matrix_xgb, nrounds = xgb.crossval$best_iteration, watchlist = list(val=test_matrix_xgb, train=train_matrix_xgb), print.every.n = 10, early.stop.round = 10, maximize = F , eval_metric = "rmse")

```


Let's find out which featuers are relatively more important in this model. 
```{r, message = FALSE, warning = FALSE}
xgb.importance(colnames(train_OHE), model = xgb.default) %>% 
  xgb.plot.importance(top_n = 25)
```











### LightGBM

```{r, message = FALSE, warning = FALSE}
train_ind <- train_set %>% select(-transactionRevenue)
test_ind <- test_set %>% select(-transactionRevenue)

train_matrix_lgbm = lgb.Dataset(data=as.matrix(train_ind), label=train_label, categorical_feature =factor_variables)
test_matrix_lgbm = lgb.Dataset(data=as.matrix(test_ind), label=test_label, categorical_feature =factor_variables)
```


```{r, message = FALSE, warning = FALSE}
params <- list(objective="regression",
              metric="rmse",
              learning_rate=0.01)

model <- lgb.cv(params, train_matrix_lgbm, 500, nfold = 5, min_data = 5,depth=4, leaves=10,  col_sample=0.3,eval_freq = 20, row_sample=0.5, learning_rate = 0.15, early_stopping_rounds = 10)


```







```{r, message = FALSE, warning = FALSE}
params <- list(objective="regression",
              metric="rmse",
              learning_rate=0.01)

lgb.model <- lgb.train(params = params,
                       data = train_matrix_lgbm,
                       valids = list(train=train_matrix_lgbm, valid=test_matrix_lgbm),
                       learning_rate=0.01,
                       nrounds=1000,
                       verbose=1,
                       early_stopping_rounds=50,
                       eval_freq=100
                      )
```










